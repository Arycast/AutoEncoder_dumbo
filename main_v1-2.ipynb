{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sigmoid (x):\n",
    "  return(1/(1+math.exp(-1*x)))\n",
    "\n",
    "def ReLu (x):\n",
    "  if (x>0):\n",
    "    return x\n",
    "  else : return 0\n",
    "\n",
    "def gradient (x):\n",
    "  return (1-sigmoid(x))*sigmoid(x)\n",
    "\n",
    "def ReLu_diff (x):\n",
    "  if (x>0):\n",
    "    return 1\n",
    "  else : return 0\n",
    "\n",
    "\n",
    "def foward_propagation(pixel_input,weight_input,weight_output,bias_input,bias_output):\n",
    "  #function input is the following :\n",
    "  #pixel_input is an 1*9 array \n",
    "  #weight_input and weight_output is an 2*9 array\n",
    "  #bias_input is an 1*2 array\n",
    "  #bias_output is an 1*9 array \n",
    "\n",
    "  #function output is the following\n",
    "  #pixel_output is an 1*9 array\n",
    "\n",
    "  #encoding side\n",
    "  encoded_1 = 0\n",
    "  encoded_2 = 0\n",
    "  for iteration in pixel_input:\n",
    "    encoded_1 = encoded_1 + pixel_input[iteration]*weight_input[0][iteration] + bias_input[0]\n",
    "    encoded_2 = encoded_2 + pixel_input[iteration]*weight_input[1][iteration] + bias_input[1]  \n",
    "  #passing through activation function (ReLu) and rewriting encoded_1 and encoded_2 value\n",
    "  encoded_1_activated = ReLu(encoded_1)\n",
    "  encoded_2_activated = ReLu(encoded_2)\n",
    "\n",
    "    #reconstruction side\n",
    "  pixel_output = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
    "  non_activated_output = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
    "\n",
    "  for iteration in range (0,9):\n",
    "    non_activated_output[iteration] = encoded_1_activated*weight_output[0][iteration] + encoded_2_activated*weight_output[1][iteration]+ bias_output[iteration]\n",
    "    pixel_output[iteration] = sigmoid(non_activated_output[iteration])\n",
    "\n",
    "  return pixel_output,encoded_1,encoded_2,non_activated_output,encoded_1_activated,encoded_2_activated\n",
    "\n",
    "def backward_propagation(pixel_input,weight_input,weight_output,bias_input,bias_output):\n",
    "\n",
    "    pixel_output,encoded_1,encoded_2,non_activated_output,encoded_1_activated,encoded_2_activated = foward_propagation(pixel_input,weight_input,weight_output,bias_input,bias_output)\n",
    "    error_output = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
    "    differential_error_output = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
    "    d_bias_output = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
    "    d_weight_output = [[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]]\n",
    "    error_middle_layer = [0.0,0.0]\n",
    "    d_weight_input = [[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]]\n",
    "    d_bias_input = [0.0,0.0]\n",
    "    learning_rate = 1.25\n",
    "\n",
    "\n",
    "    for iteration in range (0,9):\n",
    "      error_output[iteration] = -pixel_input[iteration]*(1-pixel_output[iteration])+(1-pixel_output[iteration])*pixel_output[iteration] #calculating error\n",
    "      differential_error_output[iteration] = pixel_output[iteration]*(1-pixel_output[iteration]) #calculating differrential error(idk what this for)\n",
    "      d_weight_output[0][iteration] = error_output[iteration]*encoded_1_activated #calculating output weight error 1\n",
    "      d_weight_output[1][iteration] = error_output[iteration]*encoded_2_activated #calculating output weight error 2\n",
    "      d_bias_output[iteration] = error_output[iteration] #calculating output bias differential\n",
    "      error_middle_layer[0] = error_middle_layer[0] + error_output[iteration]*weight_output[0][iteration]*ReLu_diff(encoded_1) #calculating middle layer error\n",
    "      error_middle_layer[1] = error_middle_layer[1] + error_output[iteration]*weight_output[1][iteration]*ReLu_diff(encoded_2) #calculating middle layer error\n",
    "      d_weight_input[0][iteration] = error_middle_layer[0]*pixel_input[iteration] #calculating weight input differential\n",
    "      d_weight_input[1][iteration] = error_middle_layer[1]*pixel_input[iteration] #calculating weight input differential\n",
    "      d_bias_input[0] = error_middle_layer[0]\n",
    "      d_bias_input[1] = error_middle_layer[1]\n",
    "\n",
    "    updated_weight_input = [[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]]\n",
    "    updated_weight_output = [[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]]\n",
    "    updated_bias_output = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
    "    updated_bias_input = [0.0,0.0]\n",
    "\n",
    "    for iteration in range(0,9):\n",
    "      updated_weight_output[0][iteration] = weight_output[0][iteration]- learning_rate*d_weight_output[0][iteration]\n",
    "      updated_weight_output[1][iteration] = weight_output[1][iteration]- learning_rate*d_weight_output[1][iteration]\n",
    "      updated_weight_input[0][iteration] = weight_input[0][iteration]- learning_rate*d_weight_input[0][iteration]\n",
    "      updated_weight_input[1][iteration] = weight_input[1][iteration]- learning_rate*d_weight_input[1][iteration]\n",
    "      updated_bias_output[iteration] = bias_output[iteration]- learning_rate*d_bias_output[iteration]\n",
    "    \n",
    "    updated_bias_input[0] = bias_input[0]-learning_rate*d_bias_input[0]\n",
    "    updated_bias_input[1] = bias_input[1]-learning_rate*d_bias_input[1]\n",
    "\n",
    "    return updated_weight_output,updated_weight_input,updated_bias_input,updated_bias_output,pixel_output,encoded_1_activated\n",
    "\n",
    "def cross_entropy_error(data_in,data_out): #cross entropy for measurement\n",
    "  accumulator = 0\n",
    "  for i in range (9):\n",
    "    accumulator = accumulator + (data_in[i]*math.log(data_out[i],10)+((1-data_in[i])*math.log((1-data_out[i]),10)))\n",
    "  accumulator = -(accumulator/9)\n",
    "  return accumulator\n",
    "\n",
    "#main section\n",
    "\n",
    "training_number = 10000\n",
    "error_history =[]\n",
    "temporary_error_history = 0\n",
    "x_scale = []\n",
    "\n",
    "\n",
    "#declaration and initial \n",
    "#pixel_input,weight_input,weight_output,bias_input,bias_output\n",
    "pixel_input = [1,0,1,0,1,0,1,0,1]\n",
    "pixel_output = [0,0,0,0,0,0,0,0,0]\n",
    "weight_input = [[1.3725,0.2184,1.1919,-0.3476,1.9446,0.0867,1.4450,-0.0088,1.3885],[0.8603,1.6803,0.4377,2.2810,-1.0389,2.0551,0.1210,1.7158,0.1502]]\n",
    "weight_output = [[0.3910,0.0356,0.5649,0.2035,0.3206,0.3766,0.1841,0.1040,0.4549],[0.1959,0.3785,0.9305,0.7602,0.7708,0.5967,0.7916,0.8103,0.9806]]\n",
    "bias_input = [-0.5,-0.5]\n",
    "bias_output =  [-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5,-0.5]\n",
    "\n",
    "for training in range(0,training_number):\n",
    "  weight_output,weight_input,bias_input,bias_output,pixel_output,test = backward_propagation(pixel_input,weight_input,weight_output,bias_input,bias_output)\n",
    "  temporary_error_history = cross_entropy_error(pixel_input,pixel_output)\n",
    "  error_history.append(math.log(temporary_error_history,10))\n",
    "  x_scale.append(training)\n",
    "\n",
    "\n",
    "plt.plot(x_scale,error_history, color=\"red\")  \n",
    "plt.show()\n",
    "plt.close()\n",
    "#print(pixel_output)\n",
    "#print(weight_input)\n",
    "#print(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_0001000_0100000\n"
     ]
    }
   ],
   "source": [
    "# 0_0000000_00000000 (sign_exp_fraction)\n",
    "# Converting floating point to 16-bit representation\n",
    "def float16_to_bin(num):\n",
    "   b = ['0'] * 16\n",
    "   dec_num = int(num)\n",
    "   exp = 8; frac = 7\n",
    "   float_num = num - dec_num\n",
    "\n",
    "   if (num >= 0):b[15] = '0'\n",
    "   else: b[15] = '1'\n",
    "\n",
    "   while(dec_num > 0):\n",
    "      if (dec_num % 2 == 0) : b[exp] = '0'\n",
    "      else : b[exp] = '1'\n",
    "      #print(dec_num)\n",
    "      exp += 1\n",
    "      dec_num //= 2\n",
    "   \n",
    "   for i in range (7, 0, -1):\n",
    "      float_num *= 2\n",
    "      if (float_num == 1): \n",
    "         b[frac] = '1'\n",
    "         break\n",
    "      elif (float_num > 1):\n",
    "         b[frac] = '1'\n",
    "         float_num = float_num - int(float_num)\n",
    "      else:\n",
    "         b[frac] = '0'\n",
    "      frac -= 1\n",
    "   \n",
    "   result = \"\"\n",
    "\n",
    "   for i in range(15,0,-1):\n",
    "      if (i == 15 or i == 8): result += str(b[i]) + '_'\n",
    "      else: result += str(b[i])\n",
    "   \n",
    "   return result\n",
    "\n",
    "\n",
    "# result = float16_to_bin(8.25)\n",
    "# for i in range(15,0,-1):\n",
    "#    if (i == 15 or i == 8): print(result[i], end=\"_\")\n",
    "#    else: print(result[i], end=\"\")\n",
    "print(float16_to_bin(8.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03125   448.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0009110511944006454, 0.0009399438806628558, 0.0009697519677825861, 0.0010005044009099887, 0.0010322310367548194, 0.001064962672055945, 0.001098731072924643, 0.0011335690050875116, 0.0011695102650555148, 0.001206589712246389, 0.0012448433020883745, 0.0012843081201339695, 0.0013250224172131609, 0.0013670256456563559, 0.001410358496618023, 0.0014550629385328433, 0.0015011822567369917, 0.00154876109428798, 0.0015978454940173438, 0.0016484829418512883, 0.001700722411435288, 0.0017546144100994867, 0.0018102110262026483, 0.0018675659778932803, 0.0019267346633274757, 0.0019877742123839116, 0.002050743539917378, 0.002115703400593114, 0.0021827164453451808, 0.00225184727950302, 0.0023231625226312826, 0.0023967308701289603, 0.0024726231566347743, 0.002550912421286719, 0.0026316739748845795, 0.0027149854690051763, 0.0028009269671209736, 0.002889581017773627, 0.0029810327298548972, 0.0030753698500482333, 0.0031726828424851893, 0.003273064970671631, 0.0033766123817395004, 0.003483424193080668, 0.00359360258142009, 0.0037072528743862213, 0.003824483644637211, 0.003945406806602022, 0.004070137715896128, 0.004198795271471868, 0.00433150202056399, 0.0044683842664911206, 0.004609572179374208, 0.004755199909833047, 0.004905405705722035, 0.005060332031966209, 0.005220125693558397, 0.0053849379617779605, 0.005554924703691103, 0.005730246514992078, 0.005911068856243796, 0.006097562192575309, 0.006289902136892483, 0.006488269596656705, 0.0066928509242848554, 0.006903838071221878, 0.007121428745735101, 0.007345826574477061, 0.007577241267860811, 0.007815888789288626, 0.008061991528271641, 0.008315778477474129, 0.008577485413711984, 0.008847355082930384, 0.00912563738918052, 0.009412589587609823, 0.009708476481474066, 0.010013570623173138, 0.010328152519305191, 0.010652510839726164, 0.01098694263059318, 0.011331753531361455, 0.011687257995694433, 0.012053779516236447, 0.01243165085318582, 0.012821214266594244, 0.01322282175230515, 0.013636835281429878, 0.014063627043245475, 0.014503579691381979, 0.01495708659314999, 0.015424552081841137, 0.015906391711814714, 0.016403032516163058, 0.01691491326672651, 0.01744248473620534, 0.01798620996209156, 0.018546564512117298, 0.019124036750888904, 0.019719128107346592, 0.020332353342658753, 0.020964240818127502, 0.021615332762647654, 0.02228618553922549, 0.022977369910025615, 0.023689471299374428, 0.02442309005410721, 0.025178841700601858, 0.025957357197796852, 0.026759283185443152, 0.027585282226789992, 0.02843603304485266, 0.02931223075135632, 0.030214587067393973, 0.03114383053477846, 0.03210070671700818, 0.033085978388704126, 0.03410042571231152, 0.03514484640079327, 0.03622005586497474, 0.03732688734412946, 0.03846619201832429, 0.03963883910097002, 0.040845715909949315, 0.042087727915618836, 0.04336579876390677, 0.044680870272650205, 0.04603390239924038, 0.04742587317756678, 0.048857778622174906, 0.05033063259747688, 0.05184546664977984, 0.05340332979982423, 0.05500528829345414, 0.05665242530797383, 0.05834584061168106, 0.060086650174007626, 0.06187598572364272, 0.06371499425196533, 0.0656048374590693, 0.0675466911396291, 0.06954174450582809, 0.07159119944455247, 0.07369626970604846, 0.07585818002124355, 0.07807816514495095, 0.08035746882220708, 0.08269734267503885, 0.08509904500702024, 0.08756383952305867, 0.09009299396195182, 0.09268777863937604, 0.09534946489910949, 0.09807932347046003, 0.10087862273005652, 0.1037486268663797, 0.10669059394565118, 0.10970577387797076, 0.11279540628289322, 0.11596071825396675, 0.11920292202211755, 0.12252321251815919, 0.12592276483513232, 0.12940273159163906, 0.13296424019782926, 0.13660839002621936, 0.1403362494900832, 0.14414885303274058, 0.14804719803168948, 0.15203224162217424, 0.1561048974454574, 0.1602660323277607, 0.16451646289656316, 0.16885695214168317, 0.1732882059293266, 0.17781086947804958, 0.18242552380635635, 0.18713268216242657, 0.19193278644723683, 0.19682620364309852, 0.20181322226037884, 0.2068940488158881, 0.21206880435710532, 0.2173375210470625, 0.22270013882530884, 0.22815650216092537, 0.2337063569140403, 0.23934934732271163, 0.24508501313237172, 0.25091278688527247, 0.25683199138751883, 0.26284183737131667, 0.2689414213699951, 0.2751297238231752, 0.28140560742914383, 0.2877678157610531, 0.29421497216298875, 0.3007455789412415, 0.30735801686526387, 0.31405054499180746, 0.320821300824607, 0.3276683008207139, 0.334589441253186, 0.341582499438317, 0.34864513533394575, 0.35577489351363034, 0.3629692055196168, 0.37022539259558657, 0.3775406687981454, 0.3849121444839335, 0.39233683016710835, 0.399811640739795, 0.40733340004593027, 0.4148988457967688, 0.4225046348141883, 0.43014734858584286, 0.43782349911420193, 0.4455295350395727, 0.45326184801538616, 0.461016779312316, 0.46879062662624377, 0.47657965106367606, 0.4843800842769844, 0.4921881357207956, 0.5, 0.5078118642792044, 0.5156199157230156, 0.523420348936324, 0.5312093733737563, 0.5389832206876841, 0.5467381519846138, 0.5544704649604273, 0.5621765008857981, 0.5698526514141571, 0.5774953651858118, 0.5851011542032312, 0.5926665999540697, 0.600188359260205, 0.6076631698328917, 0.6150878555160665, 0.6224593312018546, 0.6297746074044134, 0.6370307944803831, 0.6442251064863697, 0.6513548646660542, 0.658417500561683, 0.665410558746814, 0.672331699179286, 0.679178699175393, 0.6859494550081925, 0.6926419831347361, 0.6992544210587585, 0.7057850278370112, 0.712232184238947, 0.7185943925708561, 0.7248702761768248, 0.7310585786300049, 0.7371581626286834, 0.7431680086124811, 0.7490872131147275, 0.7549149868676283, 0.7606506526772884, 0.7662936430859597, 0.7718434978390747, 0.7772998611746911, 0.7826624789529376, 0.7879311956428947, 0.7931059511841119, 0.7981867777396212, 0.8031737963569016, 0.8080672135527632, 0.8128673178375735, 0.8175744761936437, 0.8221891305219503, 0.8267117940706734, 0.8311430478583168, 0.8354835371034369, 0.8397339676722393, 0.8438951025545426, 0.8479677583778257, 0.8519528019683106, 0.8558511469672594, 0.8596637505099167, 0.8633916099737806, 0.8670357598021706, 0.870597268408361, 0.8740772351648677, 0.8774767874818407, 0.8807970779778823, 0.8840392817460332, 0.8872045937171068, 0.8902942261220291, 0.8933094060543487, 0.8962513731336202, 0.8991213772699436, 0.90192067652954, 0.9046505351008906, 0.9073122213606241, 0.9099070060380482, 0.9124361604769414, 0.9149009549929797, 0.9173026573249612, 0.9196425311777929, 0.9219218348550491, 0.9241418199787566, 0.9263037302939515, 0.9284088005554476, 0.9304582554941719, 0.9324533088603709, 0.9343951625409306, 0.9362850057480346, 0.9381240142763573, 0.9399133498259924, 0.941654159388319, 0.9433475746920261, 0.9449947117065459, 0.9465966702001757, 0.94815453335022, 0.9496693674025232, 0.9511422213778251, 0.9525741268224334, 0.9539660976007597, 0.9553191297273498, 0.9566342012360932, 0.9579122720843811, 0.9591542840900507, 0.96036116089903, 0.9615338079816756, 0.9626731126558706, 0.9637799441350253, 0.9648551535992067, 0.9658995742876885, 0.9669140216112958, 0.9678992932829918, 0.9688561694652216, 0.9697854129326061, 0.9706877692486436, 0.9715639669551474, 0.9724147177732099, 0.9732407168145568, 0.9740426428022031, 0.9748211582993981, 0.9755769099458929, 0.9763105287006256, 0.9770226300899744, 0.9777138144607745, 0.9783846672373524, 0.9790357591818724, 0.9796676466573412, 0.9802808718926534, 0.9808759632491112, 0.9814534354878828, 0.9820137900379085, 0.9825575152637948, 0.9830850867332734, 0.983596967483837, 0.9840936082881853, 0.9845754479181588, 0.98504291340685, 0.985496420308618, 0.9859363729567544, 0.9863631647185701, 0.9867771782476948, 0.9871787857334058, 0.9875683491468141, 0.9879462204837635, 0.9883127420043056, 0.9886682464686385, 0.9890130573694068, 0.9893474891602738, 0.9896718474806949, 0.9899864293768268, 0.9902915235185259, 0.9905874104123901, 0.9908743626108194, 0.9911526449170697, 0.991422514586288, 0.9916842215225259, 0.9919380084717284, 0.9921841112107114, 0.9924227587321393, 0.9926541734255229, 0.9928785712542649, 0.993096161928778, 0.9933071490757153, 0.9935117304033434, 0.9937100978631075, 0.9939024378074247, 0.9940889311437562, 0.994269753485008, 0.994445075296309, 0.9946150620382221, 0.9947798743064417, 0.9949396679680339, 0.9950945942942779, 0.9952448000901669, 0.9953904278206259, 0.9955316157335089, 0.9956684979794361, 0.9958012047285281, 0.995929862284104, 0.9960545931933981, 0.9961755163553627, 0.9962927471256138, 0.9964063974185798, 0.9965165758069192, 0.9966233876182606, 0.9967269350293284, 0.9968273171575148, 0.9969246301499518, 0.9970189672701452, 0.9971104189822263, 0.9971990730328789, 0.9972850145309949, 0.9973683260251155, 0.9974490875787134, 0.9975273768433653, 0.997603269129871, 0.9976768374773688, 0.997748152720497, 0.9978172835546547, 0.9978842965994068, 0.9979492564600826, 0.998012225787616, 0.9980732653366725, 0.9981324340221067, 0.9981897889737974, 0.9982453855899006, 0.9982992775885648, 0.9983515170581486, 0.9984021545059827, 0.998451238905712, 0.998498817743263, 0.9985449370614672, 0.9985896415033819, 0.9986329743543437, 0.9986749775827868, 0.9987156918798661, 0.9987551566979116, 0.9987934102877537, 0.9988304897349445, 0.9988664309949126, 0.9989012689270753, 0.9989350373279441, 0.9989677689632452, 0.99899949559909, 0.9990302480322174, 0.9990600561193372]\n",
      "['0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000000', '0_0000000_0000001', '0_0000000_0000001', '0_0000000_0000001', '0_0000000_0000001', '0_0000000_0000001', '0_0000000_0000001', '0_0000000_0000001', '0_0000000_0000001', '0_0000000_0000001', '0_0000000_0000001', '0_0000000_0000001', '0_0000000_0000001', '0_0000000_0000001', '0_0000000_0000001', '0_0000000_0000001', '0_0000000_0000001', '0_0000000_0000001', '0_0000000_0000001', '0_0000000_0000001', '0_0000000_0000001', '0_0000000_0000001', '0_0000000_0000001', '0_0000000_0000001', '0_0000000_0000010', '0_0000000_0000010', '0_0000000_0000010', '0_0000000_0000010', '0_0000000_0000010', '0_0000000_0000010', '0_0000000_0000010', '0_0000000_0000010', '0_0000000_0000010', '0_0000000_0000010', '0_0000000_0000010', '0_0000000_0000010', '0_0000000_0000010', '0_0000000_0000011', '0_0000000_0000011', '0_0000000_0000011', '0_0000000_0000011', '0_0000000_0000011', '0_0000000_0000011', '0_0000000_0000011', '0_0000000_0000011', '0_0000000_0000011', '0_0000000_0000011', '0_0000000_0000100', '0_0000000_0000100', '0_0000000_0000100', '0_0000000_0000100', '0_0000000_0000100', '0_0000000_0000100', '0_0000000_0000100', '0_0000000_0000101', '0_0000000_0000101', '0_0000000_0000101', '0_0000000_0000101', '0_0000000_0000101', '0_0000000_0000101', '0_0000000_0000110', '0_0000000_0000110', '0_0000000_0000110', '0_0000000_0000110', '0_0000000_0000110', '0_0000000_0000111', '0_0000000_0000111', '0_0000000_0000111', '0_0000000_0000111', '0_0000000_0000111', '0_0000000_0001000', '0_0000000_0001000', '0_0000000_0001000', '0_0000000_0001000', '0_0000000_0001001', '0_0000000_0001001', '0_0000000_0001001', '0_0000000_0001001', '0_0000000_0001010', '0_0000000_0001010', '0_0000000_0001010', '0_0000000_0001011', '0_0000000_0001011', '0_0000000_0001011', '0_0000000_0001100', '0_0000000_0001100', '0_0000000_0001100', '0_0000000_0001101', '0_0000000_0001101', '0_0000000_0001110', '0_0000000_0001110', '0_0000000_0001110', '0_0000000_0001111', '0_0000000_0001111', '0_0000000_0010000', '0_0000000_0010000', '0_0000000_0010001', '0_0000000_0010001', '0_0000000_0010001', '0_0000000_0010010', '0_0000000_0010010', '0_0000000_0010011', '0_0000000_0010011', '0_0000000_0010100', '0_0000000_0010101', '0_0000000_0010101', '0_0000000_0010110', '0_0000000_0010110', '0_0000000_0010111', '0_0000000_0010111', '0_0000000_0011000', '0_0000000_0011001', '0_0000000_0011001', '0_0000000_0011010', '0_0000000_0011011', '0_0000000_0011011', '0_0000000_0011100', '0_0000000_0011101', '0_0000000_0011101', '0_0000000_0011110', '0_0000000_0011111', '0_0000000_0100000', '0_0000000_0100000', '0_0000000_0100001', '0_0000000_0100010', '0_0000000_0100011', '0_0000000_0100100', '0_0000000_0100100', '0_0000000_0100101', '0_0000000_0100110', '0_0000000_0100111', '0_0000000_0101000', '0_0000000_0101001', '0_0000000_0101001', '0_0000000_0101010', '0_0000000_0101011', '0_0000000_0101100', '0_0000000_0101101', '0_0000000_0101110', '0_0000000_0101111', '0_0000000_0110000', '0_0000000_0110001', '0_0000000_0110010', '0_0000000_0110011', '0_0000000_0110100', '0_0000000_0110101', '0_0000000_0110110', '0_0000000_0110111', '0_0000000_0111000', '0_0000000_0111001', '0_0000000_0111010', '0_0000000_0111011', '0_0000000_0111100', '0_0000000_0111101', '0_0000000_0111110', '0_0000000_0111111', '0_0000000_1000000', '0_0000000_1000000', '0_0000000_1000001', '0_0000000_1000010', '0_0000000_1000011', '0_0000000_1000100', '0_0000000_1000101', '0_0000000_1000110', '0_0000000_1000111', '0_0000000_1001000', '0_0000000_1001001', '0_0000000_1001010', '0_0000000_1001011', '0_0000000_1001100', '0_0000000_1001101', '0_0000000_1001110', '0_0000000_1001111', '0_0000000_1010000', '0_0000000_1010001', '0_0000000_1010010', '0_0000000_1010011', '0_0000000_1010100', '0_0000000_1010101', '0_0000000_1010110', '0_0000000_1010110', '0_0000000_1010111', '0_0000000_1011000', '0_0000000_1011001', '0_0000000_1011010', '0_0000000_1011011', '0_0000000_1011011', '0_0000000_1011100', '0_0000000_1011101', '0_0000000_1011110', '0_0000000_1011111', '0_0000000_1011111', '0_0000000_1100000', '0_0000000_1100001', '0_0000000_1100010', '0_0000000_1100010', '0_0000000_1100011', '0_0000000_1100100', '0_0000000_1100100', '0_0000000_1100101', '0_0000000_1100110', '0_0000000_1100110', '0_0000000_1100111', '0_0000000_1101000', '0_0000000_1101000', '0_0000000_1101001', '0_0000000_1101001', '0_0000000_1101010', '0_0000000_1101010', '0_0000000_1101011', '0_0000000_1101100', '0_0000000_1101100', '0_0000000_1101101', '0_0000000_1101101', '0_0000000_1101110', '0_0000000_1101110', '0_0000000_1101110', '0_0000000_1101111', '0_0000000_1101111', '0_0000000_1110000', '0_0000000_1110000', '0_0000000_1110001', '0_0000000_1110001', '0_0000000_1110001', '0_0000000_1110010', '0_0000000_1110010', '0_0000000_1110011', '0_0000000_1110011', '0_0000000_1110011', '0_0000000_1110100', '0_0000000_1110100', '0_0000000_1110100', '0_0000000_1110101', '0_0000000_1110101', '0_0000000_1110101', '0_0000000_1110110', '0_0000000_1110110', '0_0000000_1110110', '0_0000000_1110110', '0_0000000_1110111', '0_0000000_1110111', '0_0000000_1110111', '0_0000000_1110111', '0_0000000_1111000', '0_0000000_1111000', '0_0000000_1111000', '0_0000000_1111000', '0_0000000_1111000', '0_0000000_1111001', '0_0000000_1111001', '0_0000000_1111001', '0_0000000_1111001', '0_0000000_1111001', '0_0000000_1111010', '0_0000000_1111010', '0_0000000_1111010', '0_0000000_1111010', '0_0000000_1111010', '0_0000000_1111010', '0_0000000_1111011', '0_0000000_1111011', '0_0000000_1111011', '0_0000000_1111011', '0_0000000_1111011', '0_0000000_1111011', '0_0000000_1111011', '0_0000000_1111100', '0_0000000_1111100', '0_0000000_1111100', '0_0000000_1111100', '0_0000000_1111100', '0_0000000_1111100', '0_0000000_1111100', '0_0000000_1111100', '0_0000000_1111100', '0_0000000_1111100', '0_0000000_1111101', '0_0000000_1111101', '0_0000000_1111101', '0_0000000_1111101', '0_0000000_1111101', '0_0000000_1111101', '0_0000000_1111101', '0_0000000_1111101', '0_0000000_1111101', '0_0000000_1111101', '0_0000000_1111101', '0_0000000_1111101', '0_0000000_1111101', '0_0000000_1111110', '0_0000000_1111110', '0_0000000_1111110', '0_0000000_1111110', '0_0000000_1111110', '0_0000000_1111110', '0_0000000_1111110', '0_0000000_1111110', '0_0000000_1111110', '0_0000000_1111110', '0_0000000_1111110', '0_0000000_1111110', '0_0000000_1111110', '0_0000000_1111110', '0_0000000_1111110', '0_0000000_1111110', '0_0000000_1111110', '0_0000000_1111110', '0_0000000_1111110', '0_0000000_1111110', '0_0000000_1111110', '0_0000000_1111110', '0_0000000_1111110', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111', '0_0000000_1111111']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Floating Point</th>\n",
       "      <th>Binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000911</td>\n",
       "      <td>0_0000000_0000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000940</td>\n",
       "      <td>0_0000000_0000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000970</td>\n",
       "      <td>0_0000000_0000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001001</td>\n",
       "      <td>0_0000000_0000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001032</td>\n",
       "      <td>0_0000000_0000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>0.998935</td>\n",
       "      <td>0_0000000_1111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>0.998968</td>\n",
       "      <td>0_0000000_1111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>0.998999</td>\n",
       "      <td>0_0000000_1111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>0.999030</td>\n",
       "      <td>0_0000000_1111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>0.999060</td>\n",
       "      <td>0_0000000_1111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>448 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Floating Point             Binary\n",
       "0          0.000911  0_0000000_0000000\n",
       "1          0.000940  0_0000000_0000000\n",
       "2          0.000970  0_0000000_0000000\n",
       "3          0.001001  0_0000000_0000000\n",
       "4          0.001032  0_0000000_0000000\n",
       "..              ...                ...\n",
       "443        0.998935  0_0000000_1111111\n",
       "444        0.998968  0_0000000_1111111\n",
       "445        0.998999  0_0000000_1111111\n",
       "446        0.999030  0_0000000_1111111\n",
       "447        0.999060  0_0000000_1111111\n",
       "\n",
       "[448 rows x 2 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def sigmoid (x):\n",
    "  return(1/(1+math.exp(-1*x)))\n",
    "\n",
    "\n",
    "step = 0.5**5\n",
    "print(f\"{step}   {14 / step}\")\n",
    "high_x_range = 7\n",
    "low_x_range = -7\n",
    "\n",
    "output = []\n",
    "bin_out = []\n",
    "x = []\n",
    "accumulator_2 = 0\n",
    "\n",
    "accumulator = low_x_range\n",
    "while (accumulator < high_x_range):\n",
    "   output.append(sigmoid(accumulator))\n",
    "   #print(output)\n",
    "   x.append(accumulator)\n",
    "   accumulator = accumulator+step\n",
    "   accumulator_2 = accumulator_2+1\n",
    "   bin_out.append(float16_to_bin(sigmoid(accumulator)))\n",
    "   #bin_out += float16_to_bin(sigmoid(accumulator)) + ','\n",
    "\n",
    "#print(bin(0.1))\n",
    "\n",
    "plt.plot(x,output, color=\"red\")  \n",
    "plt.show()\n",
    "print(output)\n",
    "print(bin_out)\n",
    "\n",
    "data = {'Floating Point' : output,\n",
    "        'Binary' : bin_out}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.2\n",
      "32\n",
      "01000001101000011010000000000000\n"
     ]
    }
   ],
   "source": [
    "import struct\n",
    "import numpy\n",
    "number = 20.21\n",
    "print(numpy.float16(number))\n",
    "s = struct.pack('!f', numpy.float16(number))\n",
    "b = ''.join(format(c, '08b') for c in s)\n",
    "# for c in s:\n",
    "#    print(c)\n",
    "print(len(b))\n",
    "print(b)\n",
    "\n",
    "# def binary(num):\n",
    "#     return ''.join('{:0>8b}'.format(c) for c in struct.pack('!f', num))\n",
    "\n",
    "#print(binary(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_0001000_0100000"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
